{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"../../../figures/logo_ap.png\"  width=\"80\" height=\"80\" align=\"left\"/>\n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><blue><br><br><br><br><center>&nbsp;&nbsp;&nbsp;Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Biblioteca Alejandría</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"><center>Scraping Web de Fuentes Académicas con Agentes</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Autores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Álvaro Montenegro, alvaro.montenegro@aprendizajeprofundo.ai\n",
    "1. Daniel Montenegro, daniel.montenegro@aprendizajeprofundo.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Librerías Necesarias](#Librerías-Necesarias)\n",
    "* [Realizar Consultas](#Realizar-Consultas)\n",
    "* [Extraer Metadata](#Extraer-Metadata)\n",
    "* [Convertir en DataFrame](#Convertir-en-DataFrame)\n",
    "    * [Subsección X](#Subsección-X)\n",
    "* [Automatización](#Automatización)\n",
    "* [Conclusiones](#Conclusiones)\n",
    "* [Recomendaciones](#Recomendaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Librerías Necesarias</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import autogen\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from serpapi import GoogleSearch\n",
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "\n",
    "load_dotenv(\"../../../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Volver]](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Realizar Consultas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto de la sección X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "import requests\n",
    "\n",
    "def fetch_html(\n",
    "    url: Annotated[str, \"La URL a la que se hará la solicitud\"]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Realiza una solicitud HTTP GET usando urllib y devuelve el contenido HTML.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Realizar la solicitud\n",
    "        data = requests.get(url)\n",
    "        # Leer y decodificar el contenido\n",
    "        html = data.text\n",
    "        return html\n",
    "    except Exception as e:\n",
    "        # Manejo básico de errores\n",
    "        return f\"Error al hacer la solicitud: {str(e)}\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "type_query = \"all\"\n",
    "query = \"RAG\"\n",
    "start = 0\n",
    "max_results = 1\n",
    "sortby = \"submittedDate\"\n",
    "sortorder = \"descending\"\n",
    "url = f'http://export.arxiv.org/api/query?search_query={type_query}:{query}&start={start}&max_results={max_results}&sortBy={sortby}&sortOrder={sortorder}'\n",
    "url = f\"https://towardsdatascience.com/search?q={query}\"\n",
    "\n",
    "html_content = fetch_html(url=url)\n",
    "#print(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "What are ALL the raw pdf links and titles present in http://export.arxiv.org/api/query?search_query=all:RAG&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending?. Just give the link and title, not markdown links.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_qYsC0OHfbuBD8T38OuWdLnNF): web_scraper_agent *****\u001b[0m\n",
      "Arguments: \n",
      "{\"url\":\"http://export.arxiv.org/api/query?search_query=all:RAG&start=0&max_results=10&sortBy=submittedDate&sortOrder=descending\"}\n",
      "\u001b[32m**********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION web_scraper_agent...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_qYsC0OHfbuBD8T38OuWdLnNF) *****\u001b[0m\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
      "  <link href=\"http://arxiv.org/api/query?search_query%3Dall%3ARAG%26id_list%3D%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\n",
      "  <title type=\"html\">ArXiv Query: search_query=all:RAG&amp;id_list=&amp;start=0&amp;max_results=10</title>\n",
      "  <id>http://arxiv.org/api/j/JCFc+b/wEUWgIEysf/YgADPTs</id>\n",
      "  <updated>2024-12-15T00:00:00-05:00</updated>\n",
      "  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1178</opensearch:totalResults>\n",
      "  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n",
      "  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2412.09614v1</id>\n",
      "    <updated>2024-12-12T18:59:41Z</updated>\n",
      "    <published>2024-12-12T18:59:41Z</published>\n",
      "    <title>Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge\n",
      "  Graph-Based RAG</title>\n",
      "    <summary>  We introduce a novel approach to enhance the capabilities of text-to-image\n",
      "models by incorporating a graph-based RAG. Our system dynamically retrieves\n",
      "detailed character information and relational data from the knowledge graph,\n",
      "enabling the generation of visually accurate and contextually rich images. This\n",
      "capability significantly improves upon the limitations of existing T2I models,\n",
      "which often struggle with the accurate depiction of complex or culturally\n",
      "specific subjects due to dataset constraints. Furthermore, we propose a novel\n",
      "self-correcting mechanism for text-to-image models to ensure consistency and\n",
      "fidelity in visual outputs, leveraging the rich context from the graph to guide\n",
      "corrections. Our qualitative and quantitative experiments demonstrate that\n",
      "Context Canvas significantly enhances the capabilities of popular models such\n",
      "as Flux, Stable Diffusion, and DALL-E, and improves the functionality of\n",
      "ControlNet for fine-grained image editing tasks. To our knowledge, Context\n",
      "Canvas represents the first application of graph-based RAG in enhancing T2I\n",
      "models, representing a significant advancement for producing high-fidelity,\n",
      "context-aware multi-faceted images.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Kavana Venkatesh</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yusuf Dalva</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Ismini Lourentzou</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Pinar Yanardag</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Project Page: https://context-canvas.github.io/</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2412.09614v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.09614v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2412.08985v1</id>\n",
      "    <updated>2024-12-12T06:38:40Z</updated>\n",
      "    <published>2024-12-12T06:38:40Z</published>\n",
      "    <title>Assessing the Robustness of Retrieval-Augmented Generation Systems in\n",
      "  K-12 Educational Question Answering with Knowledge Discrepancies</title>\n",
      "    <summary>  Retrieval-Augmented Generation (RAG) systems have demonstrated remarkable\n",
      "potential as question answering systems in the K-12 Education domain, where\n",
      "knowledge is typically queried within the restricted scope of authoritative\n",
      "textbooks. However, the discrepancy between textbooks and the parametric\n",
      "knowledge in Large Language Models (LLMs) could undermine the effectiveness of\n",
      "RAG systems. To systematically investigate the robustness of RAG systems under\n",
      "such knowledge discrepancies, we present EduKDQA, a question answering dataset\n",
      "that simulates knowledge discrepancies in real applications by applying\n",
      "hypothetical knowledge updates in answers and source documents. EduKDQA\n",
      "includes 3,005 questions covering five subjects, under a comprehensive question\n",
      "typology from the perspective of context utilization and knowledge integration.\n",
      "We conducted extensive experiments on retrieval and question answering\n",
      "performance. We find that most RAG systems suffer from a substantial\n",
      "performance drop in question answering with knowledge discrepancies, while\n",
      "questions that require integration of contextual knowledge and parametric\n",
      "knowledge pose a challenge to LLMs.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Tianshi Zheng</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Weihan Li</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jiaxin Bai</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Weiqi Wang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yangqiu Song</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 pages</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2412.08985v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.08985v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2412.08593v1</id>\n",
      "    <updated>2024-12-11T18:11:39Z</updated>\n",
      "    <published>2024-12-11T18:11:39Z</published>\n",
      "    <title>Leveraging Graph-RAG and Prompt Engineering to Enhance LLM-Based\n",
      "  Automated Requirement Traceability and Compliance Checks</title>\n",
      "    <summary>  Ensuring that Software Requirements Specifications (SRS) align with\n",
      "higher-level organizational or national requirements is vital, particularly in\n",
      "regulated environments such as finance and aerospace. In these domains,\n",
      "maintaining consistency, adhering to regulatory frameworks, minimizing errors,\n",
      "and meeting critical expectations are essential for the reliable functioning of\n",
      "systems. The widespread adoption of large language models (LLMs) highlights\n",
      "their immense potential, yet there remains considerable scope for improvement\n",
      "in retrieving relevant information and enhancing reasoning capabilities. This\n",
      "study demonstrates that integrating a robust Graph-RAG framework with advanced\n",
      "prompt engineering techniques, such as Chain of Thought and Tree of Thought,\n",
      "can significantly enhance performance. Compared to baseline RAG methods and\n",
      "simple prompting strategies, this approach delivers more accurate and\n",
      "context-aware results. While this method demonstrates significant improvements\n",
      "in performance, it comes with challenges. It is both costly and more complex to\n",
      "implement across diverse contexts, requiring careful adaptation to specific\n",
      "scenarios. Additionally, its effectiveness heavily relies on having complete\n",
      "and accurate input data, which may not always be readily available, posing\n",
      "further limitations to its scalability and practicality.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Arsalan Masoudifard</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Mohammad Mowlavi Sorond</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Moein Madadi</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Mohammad Sabokrou</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Elahe Habibi</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2412.08593v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.08593v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.SE\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2412.08519v1</id>\n",
      "    <updated>2024-12-11T16:32:41Z</updated>\n",
      "    <published>2024-12-11T16:32:41Z</published>\n",
      "    <title>Bridging Relevance and Reasoning: Rationale Distillation in\n",
      "  Retrieval-Augmented Generation</title>\n",
      "    <summary>  The reranker and generator are two critical components in the\n",
      "Retrieval-Augmented Generation (i.e., RAG) pipeline, responsible for ranking\n",
      "relevant documents and generating responses. However, due to differences in\n",
      "pre-training data and objectives, there is an inevitable gap between the\n",
      "documents ranked as relevant by the reranker and those required by the\n",
      "generator to support answering the query. To address this gap, we propose\n",
      "RADIO, a novel and practical preference alignment framework with RAtionale\n",
      "DIstillatiOn. Specifically, We first propose a rationale extraction method that\n",
      "leverages the reasoning capabilities of Large Language Models (LLMs) to extract\n",
      "the rationales necessary for answering the query. Subsequently, a\n",
      "rationale-based alignment process is designed to rerank the documents based on\n",
      "the extracted rationales, and fine-tune the reranker to align the preferences.\n",
      "We conduct extensive experiments on two tasks across three datasets to\n",
      "demonstrate the effectiveness of our approach compared to baseline methods. Our\n",
      "code is released online to ease reproduction.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Pengyue Jia</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Derong Xu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Xiaopeng Li</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Zhaocheng Du</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Xiangyang Li</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Xiangyu Zhao</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yichao Wang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yuhao Wang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Huifeng Guo</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Ruiming Tang</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">under review</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2412.08519v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.08519v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2412.08054v1</id>\n",
      "    <updated>2024-12-11T03:00:24Z</updated>\n",
      "    <published>2024-12-11T03:00:24Z</published>\n",
      "    <title>Federated In-Context LLM Agent Learning</title>\n",
      "    <summary>  Large Language Models (LLMs) have revolutionized intelligent services by\n",
      "enabling logical reasoning, tool use, and interaction with external systems as\n",
      "agents. The advancement of LLMs is frequently hindered by the scarcity of\n",
      "high-quality data, much of which is inherently sensitive. Federated learning\n",
      "(FL) offers a potential solution by facilitating the collaborative training of\n",
      "distributed LLMs while safeguarding private data. However, FL frameworks face\n",
      "significant bandwidth and computational demands, along with challenges from\n",
      "heterogeneous data distributions. The emerging in-context learning capability\n",
      "of LLMs offers a promising approach by aggregating natural language rather than\n",
      "bulky model parameters. Yet, this method risks privacy leakage, as it\n",
      "necessitates the collection and presentation of data samples from various\n",
      "clients during aggregation. In this paper, we propose a novel\n",
      "privacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm,\n",
      "which to our best knowledge for the first work unleashes the power of\n",
      "in-context learning to train diverse LLM agents through FL. In our design,\n",
      "knowledge compendiums generated by a novel LLM-enhanced Knowledge Compendiums\n",
      "Generation (KCG) module are transmitted between clients and the server instead\n",
      "of model parameters in previous FL methods. Apart from that, an incredible\n",
      "Retrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU)\n",
      "module is designed and we incorporate the aggregated global knowledge\n",
      "compendium as a teacher to teach LLM agents the usage of tools. We conducted\n",
      "extensive experiments and the results show that FICAL has competitive\n",
      "performance compared to other SOTA baselines with a significant communication\n",
      "cost decrease of $\\mathbf{3.33\\times10^5}$ times.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Panlong Wu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Kangshuo Li</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Junbao Nan</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Fangxin Wang</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2412.08054v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.08054v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2412.07724v1</id>\n",
      "    <updated>2024-12-10T18:17:02Z</updated>\n",
      "    <published>2024-12-10T18:17:02Z</published>\n",
      "    <title>Granite Guardian</title>\n",
      "    <summary>  We introduce the Granite Guardian models, a suite of safeguards designed to\n",
      "provide risk detection for prompts and responses, enabling safe and responsible\n",
      "use in combination with any large language model (LLM). These models offer\n",
      "comprehensive coverage across multiple risk dimensions, including social bias,\n",
      "profanity, violence, sexual content, unethical behavior, jailbreaking, and\n",
      "hallucination-related risks such as context relevance, groundedness, and answer\n",
      "relevance for retrieval-augmented generation (RAG). Trained on a unique dataset\n",
      "combining human annotations from diverse sources and synthetic data, Granite\n",
      "Guardian models address risks typically overlooked by traditional risk\n",
      "detection models, such as jailbreaks and RAG-specific issues. With AUC scores\n",
      "of 0.871 and 0.854 on harmful content and RAG-hallucination-related benchmarks\n",
      "respectively, Granite Guardian is the most generalizable and competitive model\n",
      "available in the space. Released as open-source, Granite Guardian aims to\n",
      "promote responsible AI development across the community.\n",
      "  https://github.com/ibm-granite/granite-guardian\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Inkit Padhi</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Manish Nagireddy</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Giandomenico Cornacchia</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Subhajit Chaudhury</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Tejaswini Pedapati</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Pierre Dognin</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Keerthiram Murugesan</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Erik Miehling</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Martín Santillán Cooper</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Kieran Fraser</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Giulio Zizzo</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Muhammad Zaid Hameed</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Mark Purcell</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Michael Desmond</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Qian Pan</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Inge Vejsbjerg</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Elizabeth M. Daly</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Michael Hind</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Werner Geyer</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Ambrish Rawat</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Kush R. Varshney</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Prasanna Sattigeri</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2412.07724v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.07724v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2412.07687v1</id>\n",
      "    <updated>2024-12-10T17:20:47Z</updated>\n",
      "    <published>2024-12-10T17:20:47Z</published>\n",
      "    <title>Privacy-Preserving Customer Support: A Framework for Secure and Scalable\n",
      "  Interactions</title>\n",
      "    <summary>  The growing reliance on artificial intelligence (AI) in customer support has\n",
      "significantly improved operational efficiency and user experience. However,\n",
      "traditional machine learning (ML) approaches, which require extensive local\n",
      "training on sensitive datasets, pose substantial privacy risks and compliance\n",
      "challenges with regulations like the General Data Protection Regulation (GDPR)\n",
      "and California Consumer Privacy Act (CCPA). Existing privacy-preserving\n",
      "techniques, such as anonymization, differential privacy, and federated\n",
      "learning, address some concerns but face limitations in utility, scalability,\n",
      "and complexity. This paper introduces the Privacy-Preserving Zero-Shot Learning\n",
      "(PP-ZSL) framework, a novel approach leveraging large language models (LLMs) in\n",
      "a zero-shot learning mode. Unlike conventional ML methods, PP-ZSL eliminates\n",
      "the need for local training on sensitive data by utilizing pre-trained LLMs to\n",
      "generate responses directly. The framework incorporates real-time data\n",
      "anonymization to redact or mask sensitive information, retrieval-augmented\n",
      "generation (RAG) for domain-specific query resolution, and robust\n",
      "post-processing to ensure compliance with regulatory standards. This\n",
      "combination reduces privacy risks, simplifies compliance, and enhances\n",
      "scalability and operational efficiency. Empirical analysis demonstrates that\n",
      "the PP-ZSL framework provides accurate, privacy-compliant responses while\n",
      "significantly lowering the costs and complexities of deploying AI-driven\n",
      "customer support systems. The study highlights potential applications across\n",
      "industries, including financial services, healthcare, e-commerce, legal\n",
      "support, telecommunications, and government services. By addressing the dual\n",
      "challenges of privacy and performance, this framework establishes a foundation\n",
      "for secure, efficient, and regulatory-compliant AI applications in customer\n",
      "interactions.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Anant Prakash Awasthi</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Chandraketu Singh</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Rakshit Varma</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Sanchit Sharma</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2412.07687v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.07687v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"stat.AP\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2412.07626v1</id>\n",
      "    <updated>2024-12-10T16:05:56Z</updated>\n",
      "    <published>2024-12-10T16:05:56Z</published>\n",
      "    <title>OmniDocBench: Benchmarking Diverse PDF Document Parsing with\n",
      "  Comprehensive Annotations</title>\n",
      "    <summary>  Document content extraction is crucial in computer vision, especially for\n",
      "meeting the high-quality data needs of large language models (LLMs) and\n",
      "retrieval-augmented generation (RAG) technologies. However, current document\n",
      "parsing methods suffer from significant limitations in terms of diversity and\n",
      "comprehensive evaluation. To address these challenges, we introduce\n",
      "OmniDocBench, a novel multi-source benchmark designed to advance automated\n",
      "document content extraction. OmniDocBench includes a meticulously curated and\n",
      "annotated high-quality evaluation dataset comprising nine diverse document\n",
      "types, such as academic papers, textbooks, slides, among others. Our benchmark\n",
      "provides a flexible and comprehensive evaluation framework with 19 layout\n",
      "category labels and 14 attribute labels, enabling multi-level assessments\n",
      "across entire datasets, individual modules, or specific data types. Using\n",
      "OmniDocBench, we perform an exhaustive comparative analysis of existing modular\n",
      "pipelines and multimodal end-to-end methods, highlighting their limitations in\n",
      "handling document diversity and ensuring fair evaluation. OmniDocBench\n",
      "establishes a robust, diverse, and fair evaluation standard for the document\n",
      "content extraction field, offering crucial insights for future advancements and\n",
      "fostering the development of document parsing technologies. The codes and\n",
      "dataset is available in https://github.com/opendatalab/OmniDocBench.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Linke Ouyang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yuan Qu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Hongbin Zhou</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jiawei Zhu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Rui Zhang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Qunshu Lin</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Bin Wang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Zhiyuan Zhao</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Man Jiang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Xiaomeng Zhao</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jin Shi</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Fan Wu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Pei Chu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Minghao Liu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Zhenxiang Li</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Chao Xu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Bo Zhang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Botian Shi</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Zhongying Tu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Conghui He</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2412.07626v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.07626v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2412.07618v1</id>\n",
      "    <updated>2024-12-10T15:56:03Z</updated>\n",
      "    <published>2024-12-10T15:56:03Z</published>\n",
      "    <title>Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced\n",
      "  Retrieval-Augmented Generation on Knowledge Graphs</title>\n",
      "    <summary>  Despite the superior performance of Large language models on many NLP tasks,\n",
      "they still face significant limitations in memorizing extensive world\n",
      "knowledge. Recent studies have demonstrated that leveraging the\n",
      "Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs\n",
      "that encapsulate extensive factual data in a structured format, robustly\n",
      "enhances the reasoning capabilities of LLMs. However, deploying such systems in\n",
      "real-world scenarios presents challenges: the continuous evolution of\n",
      "non-stationary environments may lead to performance degradation and user\n",
      "satisfaction requires a careful balance of performance and responsiveness. To\n",
      "address these challenges, we introduce a Multi-objective Multi-Armed Bandit\n",
      "enhanced RAG framework, supported by multiple retrieval methods with diverse\n",
      "capabilities under rich and evolving retrieval contexts in practice. Within\n",
      "this framework, each retrieval method is treated as a distinct ``arm''. The\n",
      "system utilizes real-time user feedback to adapt to dynamic environments, by\n",
      "selecting the appropriate retrieval method based on input queries and the\n",
      "historical multi-objective performance of each arm. Extensive experiments\n",
      "conducted on two benchmark KGQA datasets demonstrate that our method\n",
      "significantly outperforms baseline methods in non-stationary settings while\n",
      "achieving state-of-the-art performance in stationary environments. Code and\n",
      "data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Xiaqiang Tang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jian Li</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Nan Du</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Sihong Xie</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">AAAI 2025</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2412.07618v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.07618v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2412.07548v1</id>\n",
      "    <updated>2024-12-10T14:39:51Z</updated>\n",
      "    <published>2024-12-10T14:39:51Z</published>\n",
      "    <title>Automatic Database Configuration Debugging using Retrieval-Augmented\n",
      "  Language Models</title>\n",
      "    <summary>  Database management system (DBMS) configuration debugging, e.g., diagnosing\n",
      "poorly configured DBMS knobs and generating troubleshooting recommendations, is\n",
      "crucial in optimizing DBMS performance. However, the configuration debugging\n",
      "process is tedious and, sometimes challenging, even for seasoned database\n",
      "administrators (DBAs) with sufficient experience in DBMS configurations and\n",
      "good understandings of the DBMS internals (e.g., MySQL or Oracle). To address\n",
      "this difficulty, we propose Andromeda, a framework that utilizes large language\n",
      "models (LLMs) to enable automatic DBMS configuration debugging. Andromeda\n",
      "serves as a natural surrogate of DBAs to answer a wide range of natural\n",
      "language (NL) questions on DBMS configuration issues, and to generate\n",
      "diagnostic suggestions to fix these issues. Nevertheless, directly prompting\n",
      "LLMs with these professional questions may result in overly generic and often\n",
      "unsatisfying answers. To this end, we propose a retrieval-augmented generation\n",
      "(RAG) strategy that effectively provides matched domain-specific contexts for\n",
      "the question from multiple sources. They come from related historical\n",
      "questions, troubleshooting manuals and DBMS telemetries, which significantly\n",
      "improve the performance of configuration debugging. To support the RAG\n",
      "strategy, we develop a document retrieval mechanism addressing heterogeneous\n",
      "documents and design an effective method for telemetry analysis. Extensive\n",
      "experiments on real-world DBMS configuration debugging datasets show that\n",
      "Andromeda significantly outperforms existing solutions.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Sibei Chen</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Ju Fan</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Bin Wu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Nan Tang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Chao Deng</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Pengyi Wang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Ye Li</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jian Tan</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Feifei Li</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jingren Zhou</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Xiaoyong Du</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2412.07548v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2412.07548v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.DB\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "</feed>\n",
      "\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "Here are the raw PDF links and titles from the given webpage:\n",
      "\n",
      "1. Title: Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG\n",
      "   PDF Link: http://arxiv.org/pdf/2412.09614v1\n",
      "\n",
      "2. Title: Assessing the Robustness of Retrieval-Augmented Generation Systems in K-12 Educational Question Answering with Knowledge Discrepancies\n",
      "   PDF Link: http://arxiv.org/pdf/2412.08985v1\n",
      "\n",
      "3. Title: Leveraging Graph-RAG and Prompt Engineering to Enhance LLM-Based Automated Requirement Traceability and Compliance Checks\n",
      "   PDF Link: http://arxiv.org/pdf/2412.08593v1\n",
      "\n",
      "4. Title: Bridging Relevance and Reasoning: Rationale Distillation in Retrieval-Augmented Generation\n",
      "   PDF Link: http://arxiv.org/pdf/2412.08519v1\n",
      "\n",
      "5. Title: Federated In-Context LLM Agent Learning\n",
      "   PDF Link: http://arxiv.org/pdf/2412.08054v1\n",
      "\n",
      "6. Title: Granite Guardian\n",
      "   PDF Link: http://arxiv.org/pdf/2412.07724v1\n",
      "\n",
      "7. Title: Privacy-Preserving Customer Support: A Framework for Secure and Scalable Interactions\n",
      "   PDF Link: http://arxiv.org/pdf/2412.07687v1\n",
      "\n",
      "8. Title: OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations\n",
      "   PDF Link: http://arxiv.org/pdf/2412.07626v1\n",
      "\n",
      "9. Title: Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs\n",
      "   PDF Link: http://arxiv.org/pdf/2412.07618v1\n",
      "\n",
      "10. Title: Automatic Database Configuration Debugging using Retrieval-Augmented Language Models\n",
      "    PDF Link: http://arxiv.org/pdf/2412.07548v1\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "### SHOULD BE REPLACED BY AN AGENT ##\n",
    "type_query = \"all\"\n",
    "query = \"RAG\"\n",
    "start = 0\n",
    "max_results = 10\n",
    "sortby = \"submittedDate\"\n",
    "sortorder = \"descending\"\n",
    "### SE DEBE CONSTRUIR EL HTML DEPENDIENDO DE LA FUENTE Y ORGANIZAR EN DICCIONARIOS LAS FUENTES ASÍ COMO LAS PALABRAS CLAVE###\n",
    "url = f'http://export.arxiv.org/api/query?search_query={type_query}:{query}&start={start}&max_results={max_results}&sortBy={sortby}&sortOrder={sortorder}'\n",
    "#url = f\"https://towardsdatascience.com/search?q={query}\"\n",
    "\n",
    "# Let's first define the assistant agent that suggests tool calls.\n",
    "assistant = ConversableAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"You are a helpful AI assistant.\"\n",
    "    \"You can help with web scraping\"\n",
    "    \"Please scrape the given link. You won't scrape twice.\"\n",
    "    \"Return 'TERMINATE' when the task is done.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    #llm_config={\"config_list\": [{\"model\": \"llama3.1:latest\", \"api_type\": \"ollama\", \"client_host\":\"http://localhost:11434\"}]},\n",
    ")\n",
    "\n",
    "# The user proxy agent is used for interacting with the assistant agent\n",
    "# and executes tool calls.\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Register the tool signature with the assistant agent.\n",
    "assistant.register_for_llm(name=\"web_scraper_agent\", description=\"A web scraping tool\")(fetch_html)\n",
    "\n",
    "# Register the tool function with the user proxy agent.\n",
    "user_proxy.register_for_execution(name=\"web_scraper_agent\")(fetch_html)\n",
    "\n",
    "chat_result = user_proxy.initiate_chat(assistant, message=f\"What are ALL the raw pdf links and titles present in {url}?. Just give the link and title, not markdown links.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'usage_including_cached_inference': {'total_cost': 0.024127499999999996,\n",
       "  'gpt-4o-2024-08-06': {'cost': 0.024127499999999996,\n",
       "   'prompt_tokens': 7891,\n",
       "   'completion_tokens': 440,\n",
       "   'total_tokens': 8331}},\n",
       " 'usage_excluding_cached_inference': {'total_cost': 0.024127499999999996,\n",
       "  'gpt-4o-2024-08-06': {'cost': 0.024127499999999996,\n",
       "   'prompt_tokens': 7891,\n",
       "   'completion_tokens': 440,\n",
       "   'total_tokens': 8331}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_result.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced System Integration: Analyzing OpenAPI Chunking for Retrieval-Augmented Generation\n",
      "CantorNet: A Sandbox for Testing Geometrical and Topological Complexity Measures\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "print(chat_result.chat_history[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'params = {\\n  \"api_key\": os.environ[\"GOOGLE_SCHOLAR_API_KEY\"],\\n  \"engine\": \"google_scholar\",\\n  \"q\": \"RAG AI\",\\n  \"hl\": \"en\"\\n}\\n\\nsearch = GoogleSearch(params)\\nresults = search.get_dict()\\nresults'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"params = {\n",
    "  \"api_key\": os.environ[\"GOOGLE_SCHOLAR_API_KEY\"],\n",
    "  \"engine\": \"google_scholar\",\n",
    "  \"q\": \"RAG AI\",\n",
    "  \"hl\": \"en\"\n",
    "}\n",
    "\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "results\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Volver]](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Extraer Metadata</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto de la sección X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, \"lxml-xml\")\n",
    "articles = soup.find_all(\"entry\")\n",
    "\n",
    "data_json = []\n",
    "for entry in articles:\n",
    "    prim_category = entry.find(\"primary_category\").get(\"term\")\n",
    "    published = entry.find(\"published\").text\n",
    "    updated = entry.find(\"updated\").text\n",
    "    title = entry.find(\"title\").text\n",
    "    summary = entry.find(\"summary\").text\n",
    "    authors = entry.find_all(\"author\")\n",
    "    authors = [auth.find(\"name\").text for auth in authors]\n",
    "    link_article = entry.select('link[title=\"pdf\"]')[0].get(\"href\")\n",
    "    data_json.append({\"primary_category\": prim_category, \n",
    "                      \"published\": published,\n",
    "                      \"updated\": updated,\n",
    "                      \"title\": title, \n",
    "                      \"summary\": summary,\n",
    "                      \"authors\": authors, \n",
    "                      \"link_article\": link_article})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Volver]](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Convertir en DataFrame</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto de la sección X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype              \n",
      "---  ------            --------------  -----              \n",
      " 0   id                20 non-null     int64              \n",
      " 1   version           20 non-null     object             \n",
      " 2   primary_category  20 non-null     object             \n",
      " 3   published         20 non-null     datetime64[ns, UTC]\n",
      " 4   updated           20 non-null     datetime64[ns, UTC]\n",
      " 5   title             20 non-null     object             \n",
      " 6   summary           20 non-null     object             \n",
      " 7   authors           20 non-null     object             \n",
      " 8   link_article      20 non-null     object             \n",
      "dtypes: datetime64[ns, UTC](2), int64(1), object(6)\n",
      "memory usage: 1.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>version</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>published</th>\n",
       "      <th>updated</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>link_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198041</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.SE</td>\n",
       "      <td>2024-11-29 16:09:43+00:00</td>\n",
       "      <td>2024-11-29 16:09:43+00:00</td>\n",
       "      <td>Advanced System Integration: Analyzing OpenAPI...</td>\n",
       "      <td>Integrating multiple (sub-)systems is essent...</td>\n",
       "      <td>[Robin D. Pesl, Jerin G. Mathew, Massimo Mecel...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.19804v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197131</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.NE</td>\n",
       "      <td>2024-11-29 14:01:34+00:00</td>\n",
       "      <td>2024-11-29 14:01:34+00:00</td>\n",
       "      <td>CantorNet: A Sandbox for Testing Topological a...</td>\n",
       "      <td>Many natural phenomena are characterized by ...</td>\n",
       "      <td>[Michal Lewandowski, Hamid Eghbalzadeh, Bernha...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.19713v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197101</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.IR</td>\n",
       "      <td>2024-11-29 13:57:07+00:00</td>\n",
       "      <td>2024-11-29 13:57:07+00:00</td>\n",
       "      <td>Know Your RAG: Dataset Taxonomy and Generation...</td>\n",
       "      <td>Retrieval Augmented Generation (RAG) systems...</td>\n",
       "      <td>[Rafael Teixeira de Lima, Shubham Gupta, Cesar...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.19710v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195541</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.HC</td>\n",
       "      <td>2024-11-29 09:07:21+00:00</td>\n",
       "      <td>2024-11-29 09:07:21+00:00</td>\n",
       "      <td>Unimib Assistant: designing a student-friendly...</td>\n",
       "      <td>Natural language processing skills of Large ...</td>\n",
       "      <td>[Chiara Antico, Stefano Giordano, Cansu Koyutu...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.19554v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195391</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>2024-11-29 08:34:07+00:00</td>\n",
       "      <td>2024-11-29 08:34:07+00:00</td>\n",
       "      <td>Knowledge Management for Automobile Failure An...</td>\n",
       "      <td>This paper presents a knowledge management s...</td>\n",
       "      <td>[Yuta Ojima, Hiroki Sakaji, Tadashi Nakamura, ...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.19539v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>195281</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2024-11-29 07:57:32+00:00</td>\n",
       "      <td>2024-11-29 07:57:32+00:00</td>\n",
       "      <td>RAGDiffusion: Faithful Cloth Generation via Ex...</td>\n",
       "      <td>Standard clothing asset generation involves ...</td>\n",
       "      <td>[Xianfeng Tan, Yuhan Li, Wenxiang Shang, Yubo ...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.19528v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>194631</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.SE</td>\n",
       "      <td>2024-11-29 04:25:31+00:00</td>\n",
       "      <td>2024-11-29 04:25:31+00:00</td>\n",
       "      <td>Towards Understanding Retrieval Accuracy and P...</td>\n",
       "      <td>Retrieval-Augmented Generation (RAG) is a pi...</td>\n",
       "      <td>[Shengming Zhao, Yuheng Huang, Jiayang Song, Z...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.19463v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>194431</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2024-11-29 03:01:05+00:00</td>\n",
       "      <td>2024-11-29 03:01:05+00:00</td>\n",
       "      <td>Auto-RAG: Autonomous Retrieval-Augmented Gener...</td>\n",
       "      <td>Iterative retrieval refers to the process in...</td>\n",
       "      <td>[Tian Yu, Shaolei Zhang, Yang Feng]</td>\n",
       "      <td>http://arxiv.org/pdf/2411.19443v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>192291</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.HC</td>\n",
       "      <td>2024-11-28 15:53:27+00:00</td>\n",
       "      <td>2024-11-28 15:53:27+00:00</td>\n",
       "      <td>Habit Coach: Customising RAG-based chatbots to...</td>\n",
       "      <td>This paper presents the iterative developmen...</td>\n",
       "      <td>[Arian Fooroogh Mand Arabi, Cansu Koyuturk, Mi...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.19229v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>189481</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.CR</td>\n",
       "      <td>2024-11-28 06:29:46+00:00</td>\n",
       "      <td>2024-11-28 06:29:46+00:00</td>\n",
       "      <td>Knowledge Database or Poison Base? Detecting R...</td>\n",
       "      <td>As Large Language Models (LLMs) are progress...</td>\n",
       "      <td>[Xue Tan, Hao Luan, Mingyu Luo, Xiaoyan Sun, P...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.18948v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>189471</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>2024-11-28 06:28:45+00:00</td>\n",
       "      <td>2024-11-28 06:28:45+00:00</td>\n",
       "      <td>ICLERB: In-Context Learning Embedding and Rera...</td>\n",
       "      <td>In-Context Learning (ICL) enables Large Lang...</td>\n",
       "      <td>[Marie Al Ghossein, Emile Contal, Alexandre Ro...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.18947v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>185831</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2024-11-27 18:27:07+00:00</td>\n",
       "      <td>2024-11-27 18:27:07+00:00</td>\n",
       "      <td>Automated Literature Review Using NLP Techniqu...</td>\n",
       "      <td>This research presents and compares multiple...</td>\n",
       "      <td>[Nurshat Fateh Ali, Md. Mahdi Mohtasim, Shakil...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.18583v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>182161</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.SE</td>\n",
       "      <td>2024-11-27 10:48:37+00:00</td>\n",
       "      <td>2024-11-27 10:48:37+00:00</td>\n",
       "      <td>Evaluating and Improving the Robustness of Sec...</td>\n",
       "      <td>Large Language Models (LLMs) are increasingl...</td>\n",
       "      <td>[Samuele Pasini, Jinhan Kim, Tommaso Aiello, R...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.18216v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>170731</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2024-11-26 03:22:01+00:00</td>\n",
       "      <td>2024-11-26 03:22:01+00:00</td>\n",
       "      <td>Path-RAG: Knowledge-Guided Key Region Retrieva...</td>\n",
       "      <td>Accurate diagnosis and prognosis assisted by...</td>\n",
       "      <td>[Awais Naeem, Tianhao Li, Huang-Ru Liao, Jiawe...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.17073v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>165231</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2024-11-25 16:10:05+00:00</td>\n",
       "      <td>2024-11-25 16:10:05+00:00</td>\n",
       "      <td>LaB-RAG: Label Boosted Retrieval Augmented Gen...</td>\n",
       "      <td>In the current paradigm of image captioning,...</td>\n",
       "      <td>[Steven Song, Anirudh Subramanyam, Irene Madej...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.16523v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>164951</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2024-11-25 15:35:51+00:00</td>\n",
       "      <td>2024-11-25 15:35:51+00:00</td>\n",
       "      <td>AtomR: Atomic Operator-Empowered Large Languag...</td>\n",
       "      <td>Recent advancements in large language models...</td>\n",
       "      <td>[Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Li, ...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.16495v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>163911</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2024-11-25 13:53:36+00:00</td>\n",
       "      <td>2024-11-25 13:53:36+00:00</td>\n",
       "      <td>Human-Calibrated Automated Testing and Validat...</td>\n",
       "      <td>This paper introduces a comprehensive framew...</td>\n",
       "      <td>[Agus Sudjianto, Aijun Zhang, Srinivas Neppall...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.16391v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>163651</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2024-11-25 13:20:19+00:00</td>\n",
       "      <td>2024-11-25 13:20:19+00:00</td>\n",
       "      <td>Multi-modal Retrieval Augmented Multi-modal Ge...</td>\n",
       "      <td>This paper investigates an intriguing task o...</td>\n",
       "      <td>[Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Yong Hu, H...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.16365v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>161331</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>2024-11-25 06:48:38+00:00</td>\n",
       "      <td>2024-11-25 06:48:38+00:00</td>\n",
       "      <td>Context Awareness Gate For Retrieval Augmented...</td>\n",
       "      <td>Retrieval Augmented Generation (RAG) has eme...</td>\n",
       "      <td>[Mohammad Hassan Heydari, Arshia Hemmat, Erfan...</td>\n",
       "      <td>http://arxiv.org/pdf/2411.16133v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>157001</td>\n",
       "      <td>1</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2024-11-24 03:56:43+00:00</td>\n",
       "      <td>2024-11-24 03:56:43+00:00</td>\n",
       "      <td>RAMIE: Retrieval-Augmented Multi-task Informat...</td>\n",
       "      <td>\\textbf{Objective:} We aimed to develop an a...</td>\n",
       "      <td>[Zaifu Zhan, Shuang Zhou, Mingchen Li, Rui Zhang]</td>\n",
       "      <td>http://arxiv.org/pdf/2411.15700v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id version primary_category                 published  \\\n",
       "0   198041       1            cs.SE 2024-11-29 16:09:43+00:00   \n",
       "1   197131       1            cs.NE 2024-11-29 14:01:34+00:00   \n",
       "2   197101       1            cs.IR 2024-11-29 13:57:07+00:00   \n",
       "3   195541       1            cs.HC 2024-11-29 09:07:21+00:00   \n",
       "4   195391       1            cs.AI 2024-11-29 08:34:07+00:00   \n",
       "5   195281       1            cs.CV 2024-11-29 07:57:32+00:00   \n",
       "6   194631       1            cs.SE 2024-11-29 04:25:31+00:00   \n",
       "7   194431       1            cs.CL 2024-11-29 03:01:05+00:00   \n",
       "8   192291       1            cs.HC 2024-11-28 15:53:27+00:00   \n",
       "9   189481       1            cs.CR 2024-11-28 06:29:46+00:00   \n",
       "10  189471       1            cs.LG 2024-11-28 06:28:45+00:00   \n",
       "11  185831       1            cs.CL 2024-11-27 18:27:07+00:00   \n",
       "12  182161       1            cs.SE 2024-11-27 10:48:37+00:00   \n",
       "13  170731       1            cs.CV 2024-11-26 03:22:01+00:00   \n",
       "14  165231       1            cs.CV 2024-11-25 16:10:05+00:00   \n",
       "15  164951       1            cs.CL 2024-11-25 15:35:51+00:00   \n",
       "16  163911       1            cs.CL 2024-11-25 13:53:36+00:00   \n",
       "17  163651       1            cs.CL 2024-11-25 13:20:19+00:00   \n",
       "18  161331       1            cs.LG 2024-11-25 06:48:38+00:00   \n",
       "19  157001       1            cs.CL 2024-11-24 03:56:43+00:00   \n",
       "\n",
       "                     updated  \\\n",
       "0  2024-11-29 16:09:43+00:00   \n",
       "1  2024-11-29 14:01:34+00:00   \n",
       "2  2024-11-29 13:57:07+00:00   \n",
       "3  2024-11-29 09:07:21+00:00   \n",
       "4  2024-11-29 08:34:07+00:00   \n",
       "5  2024-11-29 07:57:32+00:00   \n",
       "6  2024-11-29 04:25:31+00:00   \n",
       "7  2024-11-29 03:01:05+00:00   \n",
       "8  2024-11-28 15:53:27+00:00   \n",
       "9  2024-11-28 06:29:46+00:00   \n",
       "10 2024-11-28 06:28:45+00:00   \n",
       "11 2024-11-27 18:27:07+00:00   \n",
       "12 2024-11-27 10:48:37+00:00   \n",
       "13 2024-11-26 03:22:01+00:00   \n",
       "14 2024-11-25 16:10:05+00:00   \n",
       "15 2024-11-25 15:35:51+00:00   \n",
       "16 2024-11-25 13:53:36+00:00   \n",
       "17 2024-11-25 13:20:19+00:00   \n",
       "18 2024-11-25 06:48:38+00:00   \n",
       "19 2024-11-24 03:56:43+00:00   \n",
       "\n",
       "                                                title  \\\n",
       "0   Advanced System Integration: Analyzing OpenAPI...   \n",
       "1   CantorNet: A Sandbox for Testing Topological a...   \n",
       "2   Know Your RAG: Dataset Taxonomy and Generation...   \n",
       "3   Unimib Assistant: designing a student-friendly...   \n",
       "4   Knowledge Management for Automobile Failure An...   \n",
       "5   RAGDiffusion: Faithful Cloth Generation via Ex...   \n",
       "6   Towards Understanding Retrieval Accuracy and P...   \n",
       "7   Auto-RAG: Autonomous Retrieval-Augmented Gener...   \n",
       "8   Habit Coach: Customising RAG-based chatbots to...   \n",
       "9   Knowledge Database or Poison Base? Detecting R...   \n",
       "10  ICLERB: In-Context Learning Embedding and Rera...   \n",
       "11  Automated Literature Review Using NLP Techniqu...   \n",
       "12  Evaluating and Improving the Robustness of Sec...   \n",
       "13  Path-RAG: Knowledge-Guided Key Region Retrieva...   \n",
       "14  LaB-RAG: Label Boosted Retrieval Augmented Gen...   \n",
       "15  AtomR: Atomic Operator-Empowered Large Languag...   \n",
       "16  Human-Calibrated Automated Testing and Validat...   \n",
       "17  Multi-modal Retrieval Augmented Multi-modal Ge...   \n",
       "18  Context Awareness Gate For Retrieval Augmented...   \n",
       "19  RAMIE: Retrieval-Augmented Multi-task Informat...   \n",
       "\n",
       "                                              summary  \\\n",
       "0     Integrating multiple (sub-)systems is essent...   \n",
       "1     Many natural phenomena are characterized by ...   \n",
       "2     Retrieval Augmented Generation (RAG) systems...   \n",
       "3     Natural language processing skills of Large ...   \n",
       "4     This paper presents a knowledge management s...   \n",
       "5     Standard clothing asset generation involves ...   \n",
       "6     Retrieval-Augmented Generation (RAG) is a pi...   \n",
       "7     Iterative retrieval refers to the process in...   \n",
       "8     This paper presents the iterative developmen...   \n",
       "9     As Large Language Models (LLMs) are progress...   \n",
       "10    In-Context Learning (ICL) enables Large Lang...   \n",
       "11    This research presents and compares multiple...   \n",
       "12    Large Language Models (LLMs) are increasingl...   \n",
       "13    Accurate diagnosis and prognosis assisted by...   \n",
       "14    In the current paradigm of image captioning,...   \n",
       "15    Recent advancements in large language models...   \n",
       "16    This paper introduces a comprehensive framew...   \n",
       "17    This paper investigates an intriguing task o...   \n",
       "18    Retrieval Augmented Generation (RAG) has eme...   \n",
       "19    \\textbf{Objective:} We aimed to develop an a...   \n",
       "\n",
       "                                              authors  \\\n",
       "0   [Robin D. Pesl, Jerin G. Mathew, Massimo Mecel...   \n",
       "1   [Michal Lewandowski, Hamid Eghbalzadeh, Bernha...   \n",
       "2   [Rafael Teixeira de Lima, Shubham Gupta, Cesar...   \n",
       "3   [Chiara Antico, Stefano Giordano, Cansu Koyutu...   \n",
       "4   [Yuta Ojima, Hiroki Sakaji, Tadashi Nakamura, ...   \n",
       "5   [Xianfeng Tan, Yuhan Li, Wenxiang Shang, Yubo ...   \n",
       "6   [Shengming Zhao, Yuheng Huang, Jiayang Song, Z...   \n",
       "7                 [Tian Yu, Shaolei Zhang, Yang Feng]   \n",
       "8   [Arian Fooroogh Mand Arabi, Cansu Koyuturk, Mi...   \n",
       "9   [Xue Tan, Hao Luan, Mingyu Luo, Xiaoyan Sun, P...   \n",
       "10  [Marie Al Ghossein, Emile Contal, Alexandre Ro...   \n",
       "11  [Nurshat Fateh Ali, Md. Mahdi Mohtasim, Shakil...   \n",
       "12  [Samuele Pasini, Jinhan Kim, Tommaso Aiello, R...   \n",
       "13  [Awais Naeem, Tianhao Li, Huang-Ru Liao, Jiawe...   \n",
       "14  [Steven Song, Anirudh Subramanyam, Irene Madej...   \n",
       "15  [Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Li, ...   \n",
       "16  [Agus Sudjianto, Aijun Zhang, Srinivas Neppall...   \n",
       "17  [Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Yong Hu, H...   \n",
       "18  [Mohammad Hassan Heydari, Arshia Hemmat, Erfan...   \n",
       "19  [Zaifu Zhan, Shuang Zhou, Mingchen Li, Rui Zhang]   \n",
       "\n",
       "                         link_article  \n",
       "0   http://arxiv.org/pdf/2411.19804v1  \n",
       "1   http://arxiv.org/pdf/2411.19713v1  \n",
       "2   http://arxiv.org/pdf/2411.19710v1  \n",
       "3   http://arxiv.org/pdf/2411.19554v1  \n",
       "4   http://arxiv.org/pdf/2411.19539v1  \n",
       "5   http://arxiv.org/pdf/2411.19528v1  \n",
       "6   http://arxiv.org/pdf/2411.19463v1  \n",
       "7   http://arxiv.org/pdf/2411.19443v1  \n",
       "8   http://arxiv.org/pdf/2411.19229v1  \n",
       "9   http://arxiv.org/pdf/2411.18948v1  \n",
       "10  http://arxiv.org/pdf/2411.18947v1  \n",
       "11  http://arxiv.org/pdf/2411.18583v1  \n",
       "12  http://arxiv.org/pdf/2411.18216v1  \n",
       "13  http://arxiv.org/pdf/2411.17073v1  \n",
       "14  http://arxiv.org/pdf/2411.16523v1  \n",
       "15  http://arxiv.org/pdf/2411.16495v1  \n",
       "16  http://arxiv.org/pdf/2411.16391v1  \n",
       "17  http://arxiv.org/pdf/2411.16365v1  \n",
       "18  http://arxiv.org/pdf/2411.16133v1  \n",
       "19  http://arxiv.org/pdf/2411.15700v1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame.from_dict(data_json)\n",
    "columns_to_convert = ['published', 'updated']\n",
    "data_df[columns_to_convert] = data_df[columns_to_convert].apply(pd.to_datetime)\n",
    "data_df.insert(0, \"id\", data_df[\"link_article\"].str.split(\".\").str[-1].str.replace(\"v*\",\"\", regex=True))\n",
    "data_df[\"id\"] = data_df[\"id\"].astype(\"int\")\n",
    "data_df.insert(1, \"version\", data_df[\"link_article\"].str.split(\".\").str[-1].str.split(\"v\").str[-1])\n",
    "data_df.info()\n",
    "data_df.sort_values(by=\"published\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Volver]](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Subsección X</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto de la subsección X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código de la subsección X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Automatización</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatización del proceso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Uso de la Automatización</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso de la Automatización explicada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Conclusiones</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones del Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Recomendaciones</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recomendaciones del estudio hecho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Referencia]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
