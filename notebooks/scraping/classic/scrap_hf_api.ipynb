{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from huggingface_hub import HfApi\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the full list of models and their main information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()\n",
    "models = api.list_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing models: 1172145it [04:52, 4008.31it/s]                             \n"
     ]
    }
   ],
   "source": [
    "full_list = []\n",
    "for model in tqdm(models, desc='Processing models', total=1172011):\n",
    "    full_list.append({'id': model.id, 'task': model.pipeline_tag, 'created_at': model.created_at,'downloads': model.downloads, 'downloads_all_time': model.downloads_all_time, 'tags': model.tags, 'likes': model.likes, 'library_name': model.library_name, 'trending_score': model.trending_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(full_list)\n",
    "data.to_parquet('D:/Alejandria/output/models_hf.parquet')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>likes</th>\n",
       "      <th>library_name</th>\n",
       "      <th>trending_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen/QwQ-32B-Preview</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>2024-11-27 15:50:55+00:00</td>\n",
       "      <td>33626</td>\n",
       "      <td>None</td>\n",
       "      <td>[transformers, safetensors, qwen2, text-genera...</td>\n",
       "      <td>969</td>\n",
       "      <td>transformers</td>\n",
       "      <td>969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tencent/HunyuanVideo</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-01 06:00:34+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[license:other, region:us]</td>\n",
       "      <td>238</td>\n",
       "      <td>None</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lightricks/LTX-Video</td>\n",
       "      <td>image-to-video</td>\n",
       "      <td>2024-10-31 12:36:00+00:00</td>\n",
       "      <td>32304</td>\n",
       "      <td>None</td>\n",
       "      <td>[diffusers, safetensors, ltx-video, text-to-vi...</td>\n",
       "      <td>564</td>\n",
       "      <td>diffusers</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id             task                created_at  downloads  \\\n",
       "0  Qwen/QwQ-32B-Preview  text-generation 2024-11-27 15:50:55+00:00      33626   \n",
       "1  tencent/HunyuanVideo             None 2024-12-01 06:00:34+00:00          0   \n",
       "2  Lightricks/LTX-Video   image-to-video 2024-10-31 12:36:00+00:00      32304   \n",
       "\n",
       "  downloads_all_time                                               tags  \\\n",
       "0               None  [transformers, safetensors, qwen2, text-genera...   \n",
       "1               None                         [license:other, region:us]   \n",
       "2               None  [diffusers, safetensors, ltx-video, text-to-vi...   \n",
       "\n",
       "   likes  library_name  trending_score  \n",
       "0    969  transformers           969.0  \n",
       "1    238          None           238.0  \n",
       "2    564     diffusers           203.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import bs4\n",
    "import requests\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('D:/Alejandria/output/models_hf.parquet')\n",
    "data = data.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_position(model):\n",
    "    sleep(np.random.randint(1, 5))\n",
    "    url = f\"https://huggingface.co/{model}/raw/main/config.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return model, None\n",
    "    else:\n",
    "        try:\n",
    "            json_response = response.json()\n",
    "            if 'text_config' not in json_response.keys():\n",
    "                return model, json_response['max_position_embeddings']\n",
    "            else:\n",
    "                return model, json_response['text_config']['max_position_embeddings']\n",
    "        except:\n",
    "            return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting max position: 100%|██████████| 1000/1000 [02:22<00:00,  7.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the max position for each model parallelized\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "results = Parallel(n_jobs=num_cores)(delayed(get_max_position)(model) for model in tqdm(data['id'], desc='Getting max position', total=len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id, max_emb = zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['max_position'] =  max_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task</th>\n",
       "      <th>created_at</th>\n",
       "      <th>downloads</th>\n",
       "      <th>downloads_all_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>likes</th>\n",
       "      <th>library_name</th>\n",
       "      <th>trending_score</th>\n",
       "      <th>max_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen/QwQ-32B-Preview</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>2024-11-27 15:50:55+00:00</td>\n",
       "      <td>33626</td>\n",
       "      <td>None</td>\n",
       "      <td>[transformers, safetensors, qwen2, text-genera...</td>\n",
       "      <td>969</td>\n",
       "      <td>transformers</td>\n",
       "      <td>969.0</td>\n",
       "      <td>32768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tencent/HunyuanVideo</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-12-01 06:00:34+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[license:other, region:us]</td>\n",
       "      <td>238</td>\n",
       "      <td>None</td>\n",
       "      <td>238.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lightricks/LTX-Video</td>\n",
       "      <td>image-to-video</td>\n",
       "      <td>2024-10-31 12:36:00+00:00</td>\n",
       "      <td>32304</td>\n",
       "      <td>None</td>\n",
       "      <td>[diffusers, safetensors, ltx-video, text-to-vi...</td>\n",
       "      <td>564</td>\n",
       "      <td>diffusers</td>\n",
       "      <td>203.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Djrango/Qwen2vl-Flux</td>\n",
       "      <td>text-to-image</td>\n",
       "      <td>2024-11-25 02:37:41+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[diffusers, safetensors, flux, qwen2vl, stable...</td>\n",
       "      <td>352</td>\n",
       "      <td>diffusers</td>\n",
       "      <td>193.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIDC-AI/Marco-o1</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>2024-11-13 02:37:28+00:00</td>\n",
       "      <td>9709</td>\n",
       "      <td>None</td>\n",
       "      <td>[transformers, safetensors, qwen2, text-genera...</td>\n",
       "      <td>599</td>\n",
       "      <td>transformers</td>\n",
       "      <td>185.0</td>\n",
       "      <td>32768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>BioMistral/BioMistral-7B</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>2024-02-14 11:33:32+00:00</td>\n",
       "      <td>13561</td>\n",
       "      <td>None</td>\n",
       "      <td>[transformers, pytorch, tensorboard, mistral, ...</td>\n",
       "      <td>406</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>briaai/BRIA-2.3</td>\n",
       "      <td>text-to-image</td>\n",
       "      <td>2024-02-18 09:22:05+00:00</td>\n",
       "      <td>719</td>\n",
       "      <td>None</td>\n",
       "      <td>[diffusers, safetensors, text-to-image, legal ...</td>\n",
       "      <td>29</td>\n",
       "      <td>diffusers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>ShineChen1024/MagicClothing</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-02-20 02:26:57+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[arxiv:2403.01779, arxiv:2404.09512, license:c...</td>\n",
       "      <td>102</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>yanolja/EEVE-Korean-Instruct-10.8B-v1.0</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>2024-02-22 04:39:04+00:00</td>\n",
       "      <td>25650</td>\n",
       "      <td>None</td>\n",
       "      <td>[transformers, safetensors, llama, text-genera...</td>\n",
       "      <td>135</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>qualcomm/OpenPose</td>\n",
       "      <td>keypoint-detection</td>\n",
       "      <td>2024-02-25 23:02:12+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[pytorch, tflite, android, keypoint-detection,...</td>\n",
       "      <td>5</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id                task  \\\n",
       "0                       Qwen/QwQ-32B-Preview     text-generation   \n",
       "1                       tencent/HunyuanVideo                None   \n",
       "2                       Lightricks/LTX-Video      image-to-video   \n",
       "3                       Djrango/Qwen2vl-Flux       text-to-image   \n",
       "4                           AIDC-AI/Marco-o1     text-generation   \n",
       "..                                       ...                 ...   \n",
       "995                 BioMistral/BioMistral-7B     text-generation   \n",
       "996                          briaai/BRIA-2.3       text-to-image   \n",
       "997              ShineChen1024/MagicClothing                None   \n",
       "998  yanolja/EEVE-Korean-Instruct-10.8B-v1.0     text-generation   \n",
       "999                        qualcomm/OpenPose  keypoint-detection   \n",
       "\n",
       "                   created_at  downloads downloads_all_time  \\\n",
       "0   2024-11-27 15:50:55+00:00      33626               None   \n",
       "1   2024-12-01 06:00:34+00:00          0               None   \n",
       "2   2024-10-31 12:36:00+00:00      32304               None   \n",
       "3   2024-11-25 02:37:41+00:00          0               None   \n",
       "4   2024-11-13 02:37:28+00:00       9709               None   \n",
       "..                        ...        ...                ...   \n",
       "995 2024-02-14 11:33:32+00:00      13561               None   \n",
       "996 2024-02-18 09:22:05+00:00        719               None   \n",
       "997 2024-02-20 02:26:57+00:00          0               None   \n",
       "998 2024-02-22 04:39:04+00:00      25650               None   \n",
       "999 2024-02-25 23:02:12+00:00          0               None   \n",
       "\n",
       "                                                  tags  likes  library_name  \\\n",
       "0    [transformers, safetensors, qwen2, text-genera...    969  transformers   \n",
       "1                           [license:other, region:us]    238          None   \n",
       "2    [diffusers, safetensors, ltx-video, text-to-vi...    564     diffusers   \n",
       "3    [diffusers, safetensors, flux, qwen2vl, stable...    352     diffusers   \n",
       "4    [transformers, safetensors, qwen2, text-genera...    599  transformers   \n",
       "..                                                 ...    ...           ...   \n",
       "995  [transformers, pytorch, tensorboard, mistral, ...    406  transformers   \n",
       "996  [diffusers, safetensors, text-to-image, legal ...     29     diffusers   \n",
       "997  [arxiv:2403.01779, arxiv:2404.09512, license:c...    102          None   \n",
       "998  [transformers, safetensors, llama, text-genera...    135  transformers   \n",
       "999  [pytorch, tflite, android, keypoint-detection,...      5       pytorch   \n",
       "\n",
       "     trending_score  max_position  \n",
       "0             969.0       32768.0  \n",
       "1             238.0           NaN  \n",
       "2             203.0           NaN  \n",
       "3             193.0           NaN  \n",
       "4             185.0       32768.0  \n",
       "..              ...           ...  \n",
       "995             2.0       32768.0  \n",
       "996             2.0           NaN  \n",
       "997             2.0           NaN  \n",
       "998             2.0        4096.0  \n",
       "999             2.0           NaN  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get readme metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import os\n",
    "\n",
    "# Load an open-source language model\n",
    "model_name = \"tiiuae/falcon-7b-instruct\"  # Replace with the open-source model of your choice\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", trust_remote_code=True)\n",
    "qa_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def extract_metrics_from_document(document: str):\n",
    "    \"\"\"\n",
    "    Uses a language model to extract metrics information from a document.\n",
    "    \"\"\"\n",
    "    question = \"Does this document talk about the metrics of the model? If it does, return a JSON with the metrics. Use as keys the dataset it was tested on, the metric name, and the metric value.\"\n",
    "    response = qa_pipeline(f\"Document:\\n{document}\\n\\n{question}\", max_length=512, num_return_sequences=1)\n",
    "    return response[0]['generated_text']\n",
    "\n",
    "def get_readme_metrics(model):\n",
    "    sleep(np.random.randint(1, 2))\n",
    "    url = f\"https://huggingface.co/{model}/raw/main/README.md\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return response.text\n",
    "       \n",
    "def process_documents(documents_folder: str):\n",
    "    \"\"\"\n",
    "    Processes all text files in a folder and extracts metrics information.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for file_name in os.listdir(documents_folder):\n",
    "        file_path = os.path.join(documents_folder, file_name)\n",
    "        if os.path.isfile(file_path) and file_name.endswith(\".txt\"):\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                document = file.read()\n",
    "                metrics = extract_metrics_from_document(document)\n",
    "                results[file_name] = metrics\n",
    "    return results\n",
    "\n",
    "# Specify the folder containing the documents\n",
    "documents_folder = \"path_to_documents\"\n",
    "\n",
    "# Extract metrics from all documents in the folder\n",
    "metrics_results = process_documents(documents_folder)\n",
    "\n",
    "# Print results\n",
    "for file_name, metrics in metrics_results.items():\n",
    "    print(f\"Metrics for {file_name}:\")\n",
    "    print(metrics)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://huggingface.co/tencent/HunyuanVideo/raw/main/README.md\"\n",
    "response = requests.get(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
