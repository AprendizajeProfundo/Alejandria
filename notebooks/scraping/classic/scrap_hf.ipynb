{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries to web scrape\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://huggingface.co/models?p=0&sort=created'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# articles = soup.select('article', class_='overview-card-wrapper group/repo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['audio-text-to-text',\n",
       " 'image-text-to-text',\n",
       " 'visual-question-answering',\n",
       " 'document-question-answering',\n",
       " 'video-text-to-text',\n",
       " 'any-to-any',\n",
       " 'depth-estimation',\n",
       " 'image-classification',\n",
       " 'object-detection',\n",
       " 'image-segmentation',\n",
       " 'text-to-image',\n",
       " 'image-to-text',\n",
       " 'image-to-image',\n",
       " 'image-to-video',\n",
       " 'unconditional-image-generation',\n",
       " 'video-classification',\n",
       " 'text-to-video',\n",
       " 'zero-shot-image-classification',\n",
       " 'mask-generation',\n",
       " 'zero-shot-object-detection',\n",
       " 'text-to-3d',\n",
       " 'image-to-3d',\n",
       " 'image-feature-extraction',\n",
       " 'keypoint-detection',\n",
       " 'text-classification',\n",
       " 'token-classification',\n",
       " 'table-question-answering',\n",
       " 'question-answering',\n",
       " 'zero-shot-classification',\n",
       " 'translation',\n",
       " 'summarization',\n",
       " 'feature-extraction',\n",
       " 'text-generation',\n",
       " 'text2text-generation',\n",
       " 'fill-mask',\n",
       " 'sentence-similarity',\n",
       " 'text-to-speech',\n",
       " 'text-to-audio',\n",
       " 'automatic-speech-recognition',\n",
       " 'audio-to-audio',\n",
       " 'audio-classification',\n",
       " 'voice-activity-detection',\n",
       " 'tabular-classification',\n",
       " 'tabular-regression',\n",
       " 'time-series-forecasting',\n",
       " 'reinforcement-learning',\n",
       " 'robotics',\n",
       " 'graph-machine-learning']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tasks = [task.text.split('\\n') for task in soup.find_all('div',class_='flex flex-wrap')]\n",
    "tasks = [[t.replace(' ', '-').lower() for t in task] for task in tasks]\n",
    "tasks = [t for task in tasks for t in task]\n",
    "tasks = [task for task in tasks if len(task) > 1]\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-text-to-text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/48 [00:11<09:21, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-text-to-text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/48 [10:31<4:43:06, 369.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual-question-answering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 3/48 [11:55<2:59:17, 239.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document-question-answering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/48 [12:51<2:02:17, 166.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video-text-to-text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/48 [13:11<1:21:42, 114.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any-to-any\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 6/48 [21:47<2:55:26, 250.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth-estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 7/48 [22:33<2:05:37, 183.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 8/48 [31:47<3:20:59, 301.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object-detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 9/48 [41:18<4:10:45, 385.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 10/48 [44:33<3:27:00, 326.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-to-image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 11/48 [54:35<4:13:29, 411.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-to-text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 12/48 [57:06<3:19:14, 332.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-to-image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 13/48 [59:09<2:36:47, 268.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-to-video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 14/48 [59:27<1:49:18, 192.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unconditional-image-generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 15/48 [1:05:11<2:11:08, 238.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 16/48 [1:09:30<2:10:32, 244.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-to-video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 17/48 [1:10:06<1:33:57, 181.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-shot-image-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 18/48 [1:12:11<1:22:21, 164.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask-generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 19/48 [1:12:55<1:02:04, 128.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-shot-object-detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 20/48 [1:13:09<43:58, 94.22s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-to-3d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 21/48 [1:13:18<30:49, 68.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-to-3d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 22/48 [1:13:43<24:05, 55.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-feature-extraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 23/48 [1:15:05<26:28, 63.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keypoint-detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 24/48 [1:15:13<18:41, 46.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 25/48 [1:24:32<1:16:52, 200.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 26/48 [1:34:24<1:56:34, 317.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table-question-answering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 27/48 [1:34:48<1:20:27, 229.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question-answering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 28/48 [1:44:15<1:50:17, 330.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-shot-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 29/48 [1:45:11<1:18:38, 248.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 30/48 [1:54:22<1:41:43, 339.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 31/48 [1:59:59<1:35:58, 338.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature-extraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 32/48 [2:09:07<1:47:01, 401.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 33/48 [2:19:28<1:56:48, 467.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text2text-generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 34/48 [2:29:36<1:58:54, 509.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill-mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 35/48 [2:39:47<1:56:57, 539.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 36/48 [2:49:42<1:51:16, 556.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-to-speech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 37/48 [2:56:23<1:33:28, 509.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-to-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 38/48 [3:01:22<1:14:24, 446.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automatic-speech-recognition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 39/48 [3:10:37<1:11:52, 479.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-to-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 40/48 [3:20:31<1:08:29, 513.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 41/48 [3:29:50<1:01:30, 527.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voice-activity-detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 42/48 [3:30:16<37:40, 376.73s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabular-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 43/48 [3:31:06<23:13, 278.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabular-regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 44/48 [3:31:28<13:27, 201.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time-series-forecasting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 45/48 [3:31:51<07:24, 148.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinforcement-learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 46/48 [3:41:37<09:19, 279.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robotics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 47/48 [3:42:19<03:28, 208.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph-machine-learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [3:42:20<00:00, 277.94s/it]\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for task in tqdm(tasks):\n",
    "    print(task)\n",
    "    for i in range(0,100):\n",
    "        url = f'https://huggingface.co/models?pipeline_tag={task}&p={i}&sort=created'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        articles = soup.select('article', class_='overview-card-wrapper group/repo')\n",
    "        sleep(np.random.randint(1, 10))\n",
    "        if len(articles) == 0:\n",
    "            break\n",
    "        else:\n",
    "            for j in range(min(30, len(articles))):\n",
    "                time = soup.select('time')[j]['datetime']\n",
    "                model = soup.select('h4',class_='text-md truncate font-mono text-black dark:group-hover/repo:text-yellow-500 group-hover/repo:text-indigo-600 text-smd')[j].text\n",
    "                params = articles[j].get_text()\n",
    "                params = re.sub(r'\\n\\t\\t\\t\\t\\t', ' ', params)\n",
    "                params = re.sub(r'\\n\\n\\n\\n\\t\\t\\t', '•', params)\n",
    "                params = re.sub(r'\\n\\n•', '', params)\n",
    "                params = re.sub(r'\\s+', ' ', params)\n",
    "                # params = params.split('•')\n",
    "                # name, others = params[0], params[1:]\n",
    "                data_list.append({\n",
    "                    'name': model,\n",
    "                    'time': time,\n",
    "                    'params': params,\n",
    "                    'task': task\n",
    "                })\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data_list)\n",
    "data_df.to_csv('D:/Alejandria/data/data_hf.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>params</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hocuf/audio_to_speech_whisper</td>\n",
       "      <td>2024-11-28T14:16:23</td>\n",
       "      <td>hocuf/audio_to_speech_whisper•Audio-Text-to-T...</td>\n",
       "      <td>audio-text-to-text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dofbi/wolof-asr</td>\n",
       "      <td>2024-12-01T06:56:46</td>\n",
       "      <td>dofbi/wolof-asr•Audio-Text-to-Text • Updated ...</td>\n",
       "      <td>audio-text-to-text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reach-vb/test-attt-tag</td>\n",
       "      <td>2024-11-19T12:10:14</td>\n",
       "      <td>reach-vb/test-attt-tag•Audio-Text-to-Text • U...</td>\n",
       "      <td>audio-text-to-text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mradermacher/Ichigo-llama3.1-s-instruct-v0.4-i...</td>\n",
       "      <td>2024-11-19T12:53:24</td>\n",
       "      <td>mradermacher/Ichigo-llama3.1-s-instruct-v0.4-...</td>\n",
       "      <td>audio-text-to-text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mradermacher/Ichigo-llama3.1-s-instruct-v0.4-GGUF</td>\n",
       "      <td>2024-11-19T12:53:34</td>\n",
       "      <td>mradermacher/Ichigo-llama3.1-s-instruct-v0.4-...</td>\n",
       "      <td>audio-text-to-text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name                 time  \\\n",
       "0                      hocuf/audio_to_speech_whisper  2024-11-28T14:16:23   \n",
       "1                                    dofbi/wolof-asr  2024-12-01T06:56:46   \n",
       "2                             reach-vb/test-attt-tag  2024-11-19T12:10:14   \n",
       "3  mradermacher/Ichigo-llama3.1-s-instruct-v0.4-i...  2024-11-19T12:53:24   \n",
       "4  mradermacher/Ichigo-llama3.1-s-instruct-v0.4-GGUF  2024-11-19T12:53:34   \n",
       "\n",
       "                                              params                task  \n",
       "0   hocuf/audio_to_speech_whisper•Audio-Text-to-T...  audio-text-to-text  \n",
       "1   dofbi/wolof-asr•Audio-Text-to-Text • Updated ...  audio-text-to-text  \n",
       "2   reach-vb/test-attt-tag•Audio-Text-to-Text • U...  audio-text-to-text  \n",
       "3   mradermacher/Ichigo-llama3.1-s-instruct-v0.4-...  audio-text-to-text  \n",
       "4   mradermacher/Ichigo-llama3.1-s-instruct-v0.4-...  audio-text-to-text  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('D:/Alejandria/data/data_hf.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['params2'] = [re.sub(r'.* Updated.*ago|.* Updated.* \\d{2}|.* Updated.* \\d{1}|.* Updated.*,*•','', x.strip()) for x in data_df['params']]\n",
    "data_df['params2'] = data_df['params2'].apply(lambda x: x.strip().split('•'))\n",
    "# remove empty strings in lists\n",
    "data_df['params2'] = [[x for x in y if x] for y in data_df['params2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_params(row):\n",
    "    params = row['params2']\n",
    "    if len(params) == 2:\n",
    "        row['download'], row['likes'] = params[0], params[1]\n",
    "    elif  len(params) == 3:\n",
    "        row['download'], row['likes'] = params[1], params[2]\n",
    "    elif len(params) == 1:\n",
    "        row['metrics'] = params[0]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.apply(divide_params, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns=['params', 'params2'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[['name', 'task', 'time', 'download', 'likes', 'metrics']].to_csv('D:/Alejandria/data/data_hf_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>download</th>\n",
       "      <th>likes</th>\n",
       "      <th>metrics</th>\n",
       "      <th>name</th>\n",
       "      <th>task</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9644</td>\n",
       "      <td>9644</td>\n",
       "      <td>30252</td>\n",
       "      <td>68433</td>\n",
       "      <td>68433</td>\n",
       "      <td>68433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>749</td>\n",
       "      <td>154</td>\n",
       "      <td>865</td>\n",
       "      <td>68425</td>\n",
       "      <td>47</td>\n",
       "      <td>66607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cindyloo337/sabine-watercolor-lora</td>\n",
       "      <td>image-text-to-text</td>\n",
       "      <td>2024-05-07T00:34:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5445</td>\n",
       "      <td>2042</td>\n",
       "      <td>4085</td>\n",
       "      <td>2</td>\n",
       "      <td>3000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       download likes metrics                                name  \\\n",
       "count      9644  9644   30252                               68433   \n",
       "unique      749   154     865                               68425   \n",
       "top         23      1       1  cindyloo337/sabine-watercolor-lora   \n",
       "freq       5445  2042    4085                                   2   \n",
       "\n",
       "                      task                 time  \n",
       "count                68433                68433  \n",
       "unique                  47                66607  \n",
       "top     image-text-to-text  2024-05-07T00:34:01  \n",
       "freq                  3000                   14  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe(include='all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
