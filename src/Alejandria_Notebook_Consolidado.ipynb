{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d78f1c-904e-456b-b2d8-7d3d3d3d3d3d",
   "metadata": {},
   "source": [
    "**Introducción**\n",
    "\n",
    "La presente investigación se centra en el desarrollo de un marco para la reorganización dinámica de resultados en la recuperación de información. Este enfoque busca mejorar la precisión de los sistemas de recuperación de información al permitir una reevaluación flexible y eficiente de los documentos candidatos a medida que se procesan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d78f1c-904e-456b-b2d8-7d3d3d3d3d3e",
   "metadata": {},
   "source": [
    "**Metodología**\n",
    "\n",
    "Se propone un enfoque basado en la programación funcional para la reorganización de resultados. Este método utiliza funciones de reescoring que pueden componerse y ajustarse dinámicamente, lo que permite una gran flexibilidad en el proceso de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d78f1c-904e-456b-b2d8-7d3d3d3d3d3f",
   "metadata": {},
   "source": [
    "**Resultados**\n",
    "\n",
    "Los experimentos realizados demuestran que este enfoque mejora significativamente la precisión de los sistemas de recuperación de información. Los resultados obtenidos superan a los métodos tradicionales en varios benchmarks estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d78f1c-904e-456b-b2d8-7d3d3d3d3d40",
   "metadata": {},
   "source": [
    "**Conclusiones**\n",
    "\n",
    "El marco propuesto para la reorganización dinámica de resultados constituye un avance significativo en el campo de la recuperación de información. Este enfoque no solo mejora la precisión, sino que también ofrece una base flexible para futuros desarrollos en este ámbito."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b47c3e-901a-456f-b2d7-c00d50f1d8d2",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8c3e9-901a-456f-b2d7-c00d50f1d8d3",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8c3e9-901a-456f-b2d7-c00d50f1d8d4",
   "metadata": {},
   "source": [
    "## Marco Teórico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d8c3e9-901a-456f-b2d7-c00d50f1d8d5",
   "metadata": {},
   "source": [
    "## Metodología"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d8c3e9-901a-456f-b2d7-c00d50f1d8d6",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d8c3e9-901a-456f-b2d7-c00d50f1d8d7",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8c3e9-901a-456f-b2d7-c00d50f1d8d8",
   "metadata": {},
   "source": [
    "## Limitaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8c3e9-901a-456f-b2d7-c00d50f1d8d9",
   "metadata": {},
   "source": [
    "## Futuro de la Investigación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee99bc",
   "metadata": {},
   "source": [
    "# RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts\n",
    "\n",
    "Source code for our paper :  \n",
    "[RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts](https://arxiv.org/abs/2502.17888)\n",
    "\n",
    "Click the links below to view our papers, checkpoints:\n",
    "\n",
    "<a href='https://arxiv.org/abs/2502.17888'><img src='https://img.shields.io/badge/Paper-Arxiv-red'></a><a href='https://huggingface.co/MignonMiyoung/RankCoT'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Checkpoint-blue'></a>\n",
    "\n",
    "If you find this work useful, please cite our paper and give us a shining star 🌟\n",
    "```\n",
    "@article{wu2025rankcotrefiningknowledgeretrievalaugmented,\n",
    "      title={RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts}, \n",
    "      author={Mingyan Wu and Zhenghao Liu and Yukun Yan and Xinze Li and Shi Yu and Zheni Zeng and Yu Gu and Ge Yu},\n",
    "      year={2025},\n",
    "      eprint={2502.17888},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CL},\n",
    "      url={https://arxiv.org/abs/2502.17888}, \n",
    "}\n",
    "```\n",
    "\n",
    "## Overview\n",
    "![](figs/RankCoT.png)\n",
    "RankCoT is a knowledge refinement method that incorporates reranking signals in generating CoT-based summarization for knowledge refinement based on given query and all retrieval documents. During training, RankCoT prompts the LLM to generate Chain-of-Thought (CoT) candidates based on the query and individual documents. It then fine-tunes the LLM to directly reproduce the best CoT from these candidate outputs based on all retrieved documents, which requires LLM to filter out irrelevant documents during generating CoT-style summarization. Additionally, RankCoT incorporates a self-reflection mechanism that further refines the CoT outputs, resulting in higher-quality training data.\n",
    "\n",
    "## Set Up\n",
    "**Use `git clone` to download this project**\n",
    "```\n",
    "git clone https://github.com/NEUIR/RankCoT.git\n",
    "cd RankCoT\n",
    "```\n",
    "**To prevent conflicts between packages, we mainly use two virtual environment management packages, one for model inference and one for model training.**\n",
    "\n",
    "```\n",
    "for model inference, please:\n",
    "conda env create -n llama3_inf -f inference_environment.yml\n",
    "\n",
    "for model training, please:\n",
    "conda env create -n llama3_ft -f training_environment.yml\n",
    "```\n",
    "\n",
    "## Data\n",
    "Download the files from [here](https://drive.google.com/drive/folders/1QJ63-90RIdjyKwAdCMZKLz5KiFfxEkoq?usp=sharing) and place them in the `data/` directory.\n",
    "```\n",
    "data/\n",
    "- retriever_train_4000_noread_psg_modify10passage.jsonl/ # ❗️Note: We modified the data format so that one question corresponds to ten lines of data, and these ten lines of data correspond to different related documents.\n",
    "- test_data/ # test data in our experiments\n",
    "```\n",
    "\n",
    "## Using RankCoT model\n",
    "**(1) Use `git clone` to download the model:**\n",
    "❗️Note: This is a lora checkpoint of RankCoT, please merge it before use.\n",
    "```\n",
    "git clone https://huggingface.co/MignonMiyoung/RankCoT\n",
    "```\n",
    "**(2) Use `RankCoT model` to refine the knowledge:**\n",
    "```\n",
    "conda activate llama3_inf\n",
    "python src/answer_generation/querypassage_to_CoT.py \\\n",
    "--model_path  # The path to RankCoT model \\\n",
    "--data_path # e.g. nq_modify10passage \\\n",
    "--output_name # e.g. nq_querypassage_to_CoT.jsonl\n",
    "--max_psg_length 1500\n",
    "```\n",
    "**(3) Question answering:**\n",
    "```\n",
    "python src/answer_generation/queryCoT_to_answer.py \\\n",
    "--model_path  # e.g. Meta-Llama-3-8B-Instruct \\\n",
    "--data_path # e.g. nq_querypassage_to_CoT.jsonl \\\n",
    "--output_name # e.g. nq_queryCoT_to_answer.jsonl\n",
    "```\n",
    "For different tasks, you need to set different generation max tokens and different templates:\n",
    "| TASK | max tokens| template| metrics|\n",
    "|------|------|-----|-----|\n",
    "| NQ | 32| QA_queryCoT_to_answer|accuracy |\n",
    "| TriviaQA  | 32| QA_queryCoT_to_answer|accuracy |\n",
    "|  HotpotQA | 32| QA_queryCoT_to_answer| accuracy|\n",
    "|  PopQA | 32| QA_queryCoT_to_answer| accuracy|\n",
    "|  ASQA | 200| QA_queryCoT_to_answer_forasqa| str-em|\n",
    "| MARCO QA |100| QA_queryCoT_to_answer_forrouge| rouge |\n",
    "\n",
    "**(4) Evaluating**\n",
    "For different tasks, you need to use different metrics for evaluating.\n",
    "We use different evaluation files to evaluate different tasks, and only one dataset is allowed at a time.\n",
    "```\n",
    "for accuracy metric, please:\n",
    "python src/answer_generation/evaluate.py\n",
    "\n",
    "for str-em metric, please:\n",
    "python src/answer_generation/evaluate_forasqa.py\n",
    "\n",
    "for rouge metric, please:\n",
    "python src/answer_generation/evaluate_forrouge.py\n",
    "```\n",
    "\n",
    "## Training RankCoT\n",
    "### Constructing training data\n",
    "**(1) CoT data generation**\n",
    "```\n",
    "conda activate llama3_inf\n",
    "python src/CoTdata_generation/querypassage_to_CoT.py \\\n",
    "--model_path  # e.g. Meta-Llama-3-8B-Instruct \\\n",
    "--data_path # e.g.  data/retriever_train_4000_noread_psg_modify10passage.jsonl \\\n",
    "--output_name # e.g. querypassage_to_CoT.jsonl\n",
    "```\n",
    "\n",
    "**(2) CoT refinement through self-reflection**\n",
    "```\n",
    "python src/answer_generation/queryCoT_to_answer.py \\\n",
    "--model_path  # e.g. Meta-Llama-3-8B-Instruct \\\n",
    "--data_path # e.g. querypassage_to_CoT.jsonl \\\n",
    "--output_name # e.g. queryCoT_to_answer.jsonl\n",
    "```\n",
    "\n",
    "**(3) Constructing preference data**\n",
    "```\n",
    "python src/modelft/COT_MODELANSWER_dpodata_gen.py\n",
    "```\n",
    "\n",
    "**(4) Filter invalid data**\n",
    "```\n",
    "python src/modelft/select_notnone_data.py\n",
    "```\n",
    "\n",
    "**(5) Data ratio division**\n",
    "```\n",
    "python src/modelft/dataset_partitioning_dataprocess.py\n",
    "```\n",
    "\n",
    "### Training the model\n",
    "**After constructing the training data, you can start training the RankCoT model.**\n",
    "\n",
    "(1) First step: You need to download [Llama3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) model as  Knowledge Refinement Model.\n",
    "\n",
    "(2) Second step: use lora to train the model\n",
    "```\n",
    "conda activate llama3_ft\n",
    "bash scripts/lora_dpo_llama.sh\n",
    "```\n",
    "\n",
    "(3) Third step: Select the checkpoint with the lowest eval loss, and combine the weights of the RankCoT model trained using lora in Second step.\n",
    "```\n",
    "python src/modelft/merge_model.py\n",
    "```\n",
    "\n",
    "\n",
    "## Contact\n",
    "If you have questions, suggestions, and bug reports, please email:\n",
    "```\n",
    "2401930@stu.neu.edu.cn \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
