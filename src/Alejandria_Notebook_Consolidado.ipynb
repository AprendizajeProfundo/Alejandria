{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d78f1c-904e-456b-b2d8-7d3d3d3d3d3d",
   "metadata": {},
   "source": [
    "**Introducci贸n**\n",
    "\n",
    "La presente investigaci贸n se centra en el desarrollo de un marco para la reorganizaci贸n din谩mica de resultados en la recuperaci贸n de informaci贸n. Este enfoque busca mejorar la precisi贸n de los sistemas de recuperaci贸n de informaci贸n al permitir una reevaluaci贸n flexible y eficiente de los documentos candidatos a medida que se procesan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d78f1c-904e-456b-b2d8-7d3d3d3d3d3e",
   "metadata": {},
   "source": [
    "**Metodolog铆a**\n",
    "\n",
    "Se propone un enfoque basado en la programaci贸n funcional para la reorganizaci贸n de resultados. Este m茅todo utiliza funciones de reescoring que pueden componerse y ajustarse din谩micamente, lo que permite una gran flexibilidad en el proceso de decisi贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d78f1c-904e-456b-b2d8-7d3d3d3d3d3f",
   "metadata": {},
   "source": [
    "**Resultados**\n",
    "\n",
    "Los experimentos realizados demuestran que este enfoque mejora significativamente la precisi贸n de los sistemas de recuperaci贸n de informaci贸n. Los resultados obtenidos superan a los m茅todos tradicionales en varios benchmarks est谩ndar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d78f1c-904e-456b-b2d8-7d3d3d3d3d40",
   "metadata": {},
   "source": [
    "**Conclusiones**\n",
    "\n",
    "El marco propuesto para la reorganizaci贸n din谩mica de resultados constituye un avance significativo en el campo de la recuperaci贸n de informaci贸n. Este enfoque no solo mejora la precisi贸n, sino que tambi茅n ofrece una base flexible para futuros desarrollos en este 谩mbito."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b47c3e-901a-456f-b2d7-c00d50f1d8d2",
   "metadata": {},
   "source": [
    "# Introducci贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8c3e9-901a-456f-b2d7-c00d50f1d8d3",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8c3e9-901a-456f-b2d7-c00d50f1d8d4",
   "metadata": {},
   "source": [
    "## Marco Te贸rico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d8c3e9-901a-456f-b2d7-c00d50f1d8d5",
   "metadata": {},
   "source": [
    "## Metodolog铆a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d8c3e9-901a-456f-b2d7-c00d50f1d8d6",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d8c3e9-901a-456f-b2d7-c00d50f1d8d7",
   "metadata": {},
   "source": [
    "## Conclusi贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8c3e9-901a-456f-b2d7-c00d50f1d8d8",
   "metadata": {},
   "source": [
    "## Limitaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8c3e9-901a-456f-b2d7-c00d50f1d8d9",
   "metadata": {},
   "source": [
    "## Futuro de la Investigaci贸n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee99bc",
   "metadata": {},
   "source": [
    "# RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts\n",
    "\n",
    "Source code for our paper :  \n",
    "[RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts](https://arxiv.org/abs/2502.17888)\n",
    "\n",
    "Click the links below to view our papers, checkpoints:\n",
    "\n",
    "<a href='https://arxiv.org/abs/2502.17888'><img src='https://img.shields.io/badge/Paper-Arxiv-red'></a><a href='https://huggingface.co/MignonMiyoung/RankCoT'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Checkpoint-blue'></a>\n",
    "\n",
    "If you find this work useful, please cite our paper and give us a shining star \n",
    "```\n",
    "@article{wu2025rankcotrefiningknowledgeretrievalaugmented,\n",
    "      title={RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts}, \n",
    "      author={Mingyan Wu and Zhenghao Liu and Yukun Yan and Xinze Li and Shi Yu and Zheni Zeng and Yu Gu and Ge Yu},\n",
    "      year={2025},\n",
    "      eprint={2502.17888},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CL},\n",
    "      url={https://arxiv.org/abs/2502.17888}, \n",
    "}\n",
    "```\n",
    "\n",
    "## Overview\n",
    "![](figs/RankCoT.png)\n",
    "RankCoT is a knowledge refinement method that incorporates reranking signals in generating CoT-based summarization for knowledge refinement based on given query and all retrieval documents. During training, RankCoT prompts the LLM to generate Chain-of-Thought (CoT) candidates based on the query and individual documents. It then fine-tunes the LLM to directly reproduce the best CoT from these candidate outputs based on all retrieved documents, which requires LLM to filter out irrelevant documents during generating CoT-style summarization. Additionally, RankCoT incorporates a self-reflection mechanism that further refines the CoT outputs, resulting in higher-quality training data.\n",
    "\n",
    "## Set Up\n",
    "**Use `git clone` to download this project**\n",
    "```\n",
    "git clone https://github.com/NEUIR/RankCoT.git\n",
    "cd RankCoT\n",
    "```\n",
    "**To prevent conflicts between packages, we mainly use two virtual environment management packages, one for model inference and one for model training.**\n",
    "\n",
    "```\n",
    "for model inference, please:\n",
    "conda env create -n llama3_inf -f inference_environment.yml\n",
    "\n",
    "for model training, please:\n",
    "conda env create -n llama3_ft -f training_environment.yml\n",
    "```\n",
    "\n",
    "## Data\n",
    "Download the files from [here](https://drive.google.com/drive/folders/1QJ63-90RIdjyKwAdCMZKLz5KiFfxEkoq?usp=sharing) and place them in the `data/` directory.\n",
    "```\n",
    "data/\n",
    "- retriever_train_4000_noread_psg_modify10passage.jsonl/ # 锔Note: We modified the data format so that one question corresponds to ten lines of data, and these ten lines of data correspond to different related documents.\n",
    "- test_data/ # test data in our experiments\n",
    "```\n",
    "\n",
    "## Using RankCoT model\n",
    "**(1) Use `git clone` to download the model:**\n",
    "锔Note: This is a lora checkpoint of RankCoT, please merge it before use.\n",
    "```\n",
    "git clone https://huggingface.co/MignonMiyoung/RankCoT\n",
    "```\n",
    "**(2) Use `RankCoT model` to refine the knowledge:**\n",
    "```\n",
    "conda activate llama3_inf\n",
    "python src/answer_generation/querypassage_to_CoT.py \\\n",
    "--model_path  # The path to RankCoT model \\\n",
    "--data_path # e.g. nq_modify10passage \\\n",
    "--output_name # e.g. nq_querypassage_to_CoT.jsonl\n",
    "--max_psg_length 1500\n",
    "```\n",
    "**(3) Question answering:**\n",
    "```\n",
    "python src/answer_generation/queryCoT_to_answer.py \\\n",
    "--model_path  # e.g. Meta-Llama-3-8B-Instruct \\\n",
    "--data_path # e.g. nq_querypassage_to_CoT.jsonl \\\n",
    "--output_name # e.g. nq_queryCoT_to_answer.jsonl\n",
    "```\n",
    "For different tasks, you need to set different generation max tokens and different templates:\n",
    "| TASK | max tokens| template| metrics|\n",
    "|------|------|-----|-----|\n",
    "| NQ | 32| QA_queryCoT_to_answer|accuracy |\n",
    "| TriviaQA  | 32| QA_queryCoT_to_answer|accuracy |\n",
    "|  HotpotQA | 32| QA_queryCoT_to_answer| accuracy|\n",
    "|  PopQA | 32| QA_queryCoT_to_answer| accuracy|\n",
    "|  ASQA | 200| QA_queryCoT_to_answer_forasqa| str-em|\n",
    "| MARCO QA |100| QA_queryCoT_to_answer_forrouge| rouge |\n",
    "\n",
    "**(4) Evaluating**\n",
    "For different tasks, you need to use different metrics for evaluating.\n",
    "We use different evaluation files to evaluate different tasks, and only one dataset is allowed at a time.\n",
    "```\n",
    "for accuracy metric, please:\n",
    "python src/answer_generation/evaluate.py\n",
    "\n",
    "for str-em metric, please:\n",
    "python src/answer_generation/evaluate_forasqa.py\n",
    "\n",
    "for rouge metric, please:\n",
    "python src/answer_generation/evaluate_forrouge.py\n",
    "```\n",
    "\n",
    "## Training RankCoT\n",
    "### Constructing training data\n",
    "**(1) CoT data generation**\n",
    "```\n",
    "conda activate llama3_inf\n",
    "python src/CoTdata_generation/querypassage_to_CoT.py \\\n",
    "--model_path  # e.g. Meta-Llama-3-8B-Instruct \\\n",
    "--data_path # e.g.  data/retriever_train_4000_noread_psg_modify10passage.jsonl \\\n",
    "--output_name # e.g. querypassage_to_CoT.jsonl\n",
    "```\n",
    "\n",
    "**(2) CoT refinement through self-reflection**\n",
    "```\n",
    "python src/answer_generation/queryCoT_to_answer.py \\\n",
    "--model_path  # e.g. Meta-Llama-3-8B-Instruct \\\n",
    "--data_path # e.g. querypassage_to_CoT.jsonl \\\n",
    "--output_name # e.g. queryCoT_to_answer.jsonl\n",
    "```\n",
    "\n",
    "**(3) Constructing preference data**\n",
    "```\n",
    "python src/modelft/COT_MODELANSWER_dpodata_gen.py\n",
    "```\n",
    "\n",
    "**(4) Filter invalid data**\n",
    "```\n",
    "python src/modelft/select_notnone_data.py\n",
    "```\n",
    "\n",
    "**(5) Data ratio division**\n",
    "```\n",
    "python src/modelft/dataset_partitioning_dataprocess.py\n",
    "```\n",
    "\n",
    "### Training the model\n",
    "**After constructing the training data, you can start training the RankCoT model.**\n",
    "\n",
    "(1) First step: You need to download [Llama3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) model as  Knowledge Refinement Model.\n",
    "\n",
    "(2) Second step: use lora to train the model\n",
    "```\n",
    "conda activate llama3_ft\n",
    "bash scripts/lora_dpo_llama.sh\n",
    "```\n",
    "\n",
    "(3) Third step: Select the checkpoint with the lowest eval loss, and combine the weights of the RankCoT model trained using lora in Second step.\n",
    "```\n",
    "python src/modelft/merge_model.py\n",
    "```\n",
    "\n",
    "\n",
    "## Contact\n",
    "If you have questions, suggestions, and bug reports, please email:\n",
    "```\n",
    "2401930@stu.neu.edu.cn \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
